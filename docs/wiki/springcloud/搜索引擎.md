<<<<<<< HEAD
## Elasticsearch 

1，Elasticsearch 是一个实时的分布式存储、搜索、分析的引擎。

介绍那儿有几个关键字：

实时

分布式

搜索

分析


2，首先我们得知道为什么Elasticsearch为什么可以实现快速的“模糊匹配”/“相关性查询”，实际上是你写入数据到Elasticsearch的时候会进行分词。

还是以上图为例，上图出现了4次“算法”这个词，我们能不能根据这次词为它找他对应的目录？Elasticsearch正是这样干的，如果我们根据上图来做这个事，会得到类似这样的结果：

算法  ->2,13,42,56

这代表着“算法”这个词肯定是在第二页、第十三页、第四十二页、第五十六页出现过。这种根据某个词(不完整的条件)再查找对应记录，叫做倒排索引


3，众所周知，世界上有这么多的语言，那Elasticsearch怎么切分这些词呢？，Elasticsearch内置了一些分词器

Standard  Analyzer 。按词切分，将词小写

Simple Analyzer。按非字母过滤（符号被过滤掉），将词小写

WhitespaceAnalyzer。按照空格切分，不转小写

….等等等

Elasticsearch分词器主要由三部分组成：

􏱀􏰉􏰂􏰈􏰂􏰆􏰄Character Filters（文本过滤器，去除HTML）

Tokenizer（按照规则切分，比如空格）

TokenFilter（将切分后的词进行处理，比如转成小写）

显然，Elasticsearch是老外写的，内置的分词器都是英文类的，而我们用户搜索的时候往往搜的是中文，现在中文分词器用得最多的就是IK。

<<<<<<< HEAD
1.为什么要使用Elasticsearch?
​ 　　因为在我们商城中的数据，将来会非常多，所以采用以往的模糊查询，模糊查询前置配置，会放弃索引，导致商品查询是全表扫面，在百万级别的数据库中，效率非常低下，而我们使用ES做一个全文索引，我们将经常查询的商品的某些字段，比如说商品名，描述、价格还有id这些字段我们放入我们索引库里，可以提高查询速度。

2.Elasticsearch是如何实现Master选举的？
　　Elasticsearch的选主是ZenDiscovery模块负责的，主要包含Ping（节点之间通过这个RPC来发现彼此）和Unicast（单播模块包含一个主机列表以控制哪些节点需要ping通）这两部分；
　　对所有可以成为master的节点（node.master: true）根据nodeId字典排序，每次选举每个节点都把自己所知道节点排一次序，然后选出第一个（第0位）节点，暂且认为它是master节点。
　　如果对某个节点的投票数达到一定的值（可以成为master节点数n/2+1）并且该节点自己也选举自己，那这个节点就是master。否则重新选举一直到满足上述条件。
补充：master节点的职责主要包括集群、节点和索引的管理，不负责文档级别的管理；data节点可以关闭http功能。

3.Elasticsearch中的节点（比如共20个），其中的10个选了一个master，另外10个选了另一个master，怎么办？
　　当集群master候选数量不小于3个时，可以通过设置最少投票通过数量（discovery.zen.minimum_master_nodes）超过所有候选节点一半以上来解决脑裂问题；
当候选数量为两个时，只能修改为唯一的一个master候选，其他作为data节点，避免脑裂问题。

4.详细描述一下Elasticsearch索引文档的过程。
　　协调节点默认使用文档ID参与计算（也支持通过routing），以便为路由提供合适的分片。
　　shard = hash(document_id) % (num_of_primary_shards)
　　当分片所在的节点接收到来自协调节点的请求后，会将请求写入到Memory Buffer，然后定时（默认是每隔1秒）写入到Filesystem Cache，这个从Momery Buffer到Filesystem 　　Cache的过程就叫做refresh；
　　当然在某些情况下，存在Momery Buffer和Filesystem Cache的数据可能会丢失，ES是通过translog的机制来保证数据的可靠性的。其实现机制是接收到请求后，同时也会写入到translog中，当Filesystem cache中的数据写入到磁盘中时，才会清除掉，这个过程叫做flush；
　　在flush过程中，内存中的缓冲将被清除，内容被写入一个新段，段的fsync将创建一个新的提交点，并将内容刷新到磁盘，旧的translog将被删除并开始一个新的translog。
　　flush触发的时机是定时触发（默认30分钟）或者translog变得太大（默认为512M）时；

5.详细描述一下Elasticsearch更新和删除文档的过程
　　删除和更新也都是写操作，但是Elasticsearch中的文档是不可变的，因此不能被删除或者改动以展示其变更；
　　磁盘上的每个段都有一个相应的.del文件。当删除请求发送后，文档并没有真的被删除，而是在.del文件中被标记为删除。该文档依然能匹配查询，但是会在结果中被过滤掉。当段合并时，在.del文件中被标记为删除的文档将不会被写入新段。
　　在新的文档被创建时，Elasticsearch会为该文档指定一个版本号，当执行更新时，旧版本的文档在.del文件中被标记为删除，新版本的文档被索引到一个新段。旧版本的文档依然能匹配查询，但是会在结果中被过滤掉。

6.详细描述一下Elasticsearch搜索的过程
　　搜索被执行成一个两阶段过程，我们称之为 Query Then Fetch；
　　在初始查询阶段时，查询会广播到索引中每一个分片拷贝（主分片或者副本分片）。 每个分片在本地执行搜索并构建一个匹配文档的大小为 from + size 的优先队列。PS：在搜索的时候是会查询Filesystem Cache的，但是有部分数据还在Memory Buffer，所以搜索是近实时的。
　　每个分片返回各自优先队列中 所有文档的 ID 和排序值 给协调节点，它合并这些值到自己的优先队列中来产生一个全局排序后的结果列表。
　　接下来就是 取回阶段，协调节点辨别出哪些文档需要被取回并向相关的分片提交多个 GET 请求。每个分片加载并 丰富 文档，如果有需要的话，接着返回文档给协调节点。一旦所有的文档都被取回了，协调节点返回结果给客户端。
　　补充：Query Then Fetch的搜索类型在文档相关性打分的时候参考的是本分片的数据，这样在文档数量较少的时候可能不够准确，DFS Query Then Fetch增加了一个预查询的处理，询问Term和Document frequency，这个评分更准确，但是性能会变差。

9.Elasticsearch对于大数据量（上亿量级）的聚合如何实现？
​ 　　Elasticsearch 提供的首个近似聚合是cardinality 度量。它提供一个字段的基数，即该字段的distinct或者unique值的数目。它是基于HLL算法的。HLL 会先对我们的输入作哈希运算，然后根据哈希运算的结果中的 bits 做概率估算从而得到基数。其特点是：可配置的精度，用来控制内存的使用（更精确 ＝ 更多内存）；小的数据集精度是非常高的；我们可以通过配置参数，来设置去重需要的固定内存使用量。无论数千还是数十亿的唯一值，内存使用量只与你配置的精确度相关 .

10.在并发情况下，Elasticsearch如果保证读写一致？
　　可以通过版本号使用乐观并发控制，以确保新版本不会被旧版本覆盖，由应用层来处理具体的冲突；
　　另外对于写操作，一致性级别支持quorum/one/all，默认为quorum，即只有当大多数分片可用时才允许写操作。但即使大多数可用，也可能存在因为网络等原因导致写入副本失败，这样该副本被认为故障，分片将会在一个不同的节点上重建。
　　对于读操作，可以设置replication为sync(默认)，这使得操作在主分片和副本分片都完成后才会返回；如果设置replication为async时，也可以通过设置搜索请求参数_preference为primary来查询主分片，确保文档是最新版本。

14.ElasticSearch中的集群、节点、索引、文档、类型是什么？
　　群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。
　　节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。
　　索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =>数据库 　　         ElasticSearch =>索引
　　文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL => Databases => 　             Tables => Columns / Rows ElasticSearch => Indices => Types =>具有属性的文档
　　类型是索引的逻辑类别/分区，其语义完全取决于用户。

15.ElasticSearch中的分片是什么?
　　在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。

　　索引 - 在Elasticsearch中，索引是文档的集合。
　　分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。

 

 

问题一：

什么是ElasticSearch？ 

Elasticsearch是一个基于Lucene的搜索引擎。它提供了具有HTTP Web界面和无架构JSON文档的分布式，多租户能力的全文搜索引擎。Elasticsearch是用Java开发的，根据Apache许可条款作为开源发布。

 

问题三：

### 倒排索引 

倒排索引是搜索引擎的核心。搜索引擎的主要目标是在查找发生搜索条件的文档时提供快速搜索。倒排索引是一种像数据结构一样的散列图，可将用户从单词导向文档或网页。它是搜索引擎的核心。其主要目标是快速搜索从数百万文件中查找数据。 

 

问题四：

#### 集群、节点、索引、文档、类型

群集是一个或多个节点（服务器）的集合，它们共同保存您的整个数据，并提供跨所有节点的联合索引和搜索功能。群集由唯一名称标识，默认情况下为“elasticsearch”。此名称很重要，因为如果节点设置为按名称加入群集，则该节点只能是群集的一部分。

节点是属于集群一部分的单个服务器。它存储数据并参与群集索引和搜索功能。

索引就像关系数据库中的“数据库”。它有一个定义多种类型的映射。索引是逻辑名称空间，映射到一个或多个主分片，并且可以有零个或多个副本分片。 MySQL =>数据库 ElasticSearch =>索引

文档类似于关系数据库中的一行。不同之处在于索引中的每个文档可以具有不同的结构（字段），但是对于通用字段应该具有相同的数据类型。 MySQL => Databases => Tables => Columns / Rows ElasticSearch => Indices => Types =>具有属性的文档

类型是索引的逻辑类别/分区，其语义完全取决于用户。

 

问题五：

ElasticSearch是否有架构？

ElasticSearch可以有一个架构。架构是描述文档类型以及如何处理文档的不同字段的一个或多个字段的描述。Elasticsearch中的架构是一种映射，它描述了JSON文档中的字段及其数据类型，以及它们应该如何在Lucene索引中进行索引。因此，在Elasticsearch术语中，我们通常将此模式称为“映射”。 

Elasticsearch具有架构灵活的能力，这意味着可以在不明确提供架构的情况下索引文档。如果未指定映射，则默认情况下，Elasticsearch会在索引期间检测文档中的新字段时动态生成一个映射。

 

问题六：

ElasticSearch中的分片是什么？ 

在大多数环境中，每个节点都在单独的盒子或虚拟机上运行。 

索引 - 在Elasticsearch中，索引是文档的集合。 

分片 -因为Elasticsearch是一个分布式搜索引擎，所以索引通常被分割成分布在多个节点上的被称为分片的元素。

 

问题七：

ElasticSearch中的副本是什么？

一个索引被分解成碎片以便于分发和扩展。副本是分片的副本。一个节点是一个属于一个集群的ElasticSearch的运行实例。一个集群由一个或多个共享相同集群名称的节点组成。

 

问题八：

ElasticSearch中的分析器是什么？

在ElasticSearch中索引数据时，数据由为索引定义的Analyzer在内部进行转换。 分析器由一个Tokenizer和零个或多个TokenFilter组成。编译器可以在一个或多个CharFilter之前。分析模块允许您在逻辑名称下注册分析器，然后可以在映射定义或某些API中引用它们。

Elasticsearch附带了许多可以随时使用的预建分析器。或者，您可以组合内置的字符过滤器，编译器和过滤器器来创建自定义分析器。

 

问题九：

什么是ElasticSearch中的编译器？

编译器用于将字符串分解为术语或标记流。一个简单的编译器可能会将字符串拆分为任何遇到空格或标点的地方。Elasticsearch有许多内置标记器，可用于构建自定义分析器。

 

问题十一：

启用属性，索引和存储的用途是什么？

enabled属性适用于各类ElasticSearch特定/创建领域，如index和size。用户提供的字段没有“已启用”属性。 存储意味着数据由Lucene存储，如果询问，将返回这些数据。

存储字段不一定是可搜索的。默认情况下，字段不存储，但源文件是完整的。因为您希望使用默认值(这是有意义的)，所以不要设置store属性 该指数属性用于搜索。

索引属性只能用于搜索。只有索引域可以进行搜索。差异的原因是在分析期间对索引字段进行了转换，因此如果需要的话，您不能检索原始数据。

=======
4，es大量数据(数十亿级别)时，如何提高查询效率
　　1. filesystem cache
　　　　往es写入数据时，其实就是写入到磁盘中的。而es的搜索引擎底层是严重依赖于文件系统缓存的，es所有的indx segment file索引数据文件就存在这里面，如果filesystem cache的内存够大，那么你搜索的时候基本就是走内存的，性能会很高。打个比方说：
　　　　es节点有3台机器，每台机器，看起来内存很多，64G，总内存，64 * 3 = 192g；每台机器给es jvm heap是32G，那么剩下来留给filesystem cache的就是每台机器才32g，总共集群里给filesystem cache的就是32 * 3 = 96g内存。如果有1T的数据量，那就只有10%的索引文件被存到file cache里面去，效率肯定是比较低的，就是你的机器的内存，至少可以容纳你的总数据量的一半。
　　2. 数据预热/冷热分离
　　　　预热：比如file cache有50g内存，而数据超过了100g怎么办呢？我们可以做一个后台系统定时去拉取一些容易被人访问的数据。因为我们查询es时，它会重新记录这个索引的信息、进行排序将这些数据放到file cache中。
　　　　冷热分离：大量不搜索的字段拆到别的index里面去，就有点像mysql的垂直拆分，这样可以确保热数据在被预热之后，尽量都让他们留在filesystem os cache里，别让冷数据给冲刷掉。热数据可能就占总数据量的10%，此时数据量很少，几乎全都保留在filesystem cache里面了，就可以确保热数据的访问性能是很高的。
　　3. document模型设计
　　　　es里面的复杂的关联查询，复杂的查询语法，尽量别用，一旦用了性能一般都不太好。有关联的最好写入es的时候，搞成两个索引，order索引，orderItem索引，order索引里面就包含id order_code total_price；orderItem索引直接包含id order_code total_price id order_id goods_id purchase_count price，这样就不需要es的语法来完成join了。
　　4. 分页性能优化
　　　　es的分页是较坑的，假如你每页是10条数据，你现在要查询第100页，实际上是会把每个shard上存储的前1000条数据都查到一个协调节点上，如果你有个5个shard，那么就有5000条数据，接着协调节点对这5000条数据进行一些合并、处理，再获取到最终第100页的10条数据。翻页的时候，翻的越深，每个shard返回的数据就越多，而且协调节点处理的时间越长。非常坑爹。所以用es做分页的时候，你会发现越翻到后面，就越是慢。有2个折中的优化方案：
　　　　1 不允许分页，直接把数据给客户端(这么说估计会被打)。
　　　　2 允许一页页的翻但是不允许选择页数，就像app的推荐商品一样。用scroll api一页页去刷，scroll的原理实际上是保留一个数据快照，然后在一定时间内，你如果不断的滑动往后翻页的时候，类似于你现在在浏览微博，不断往下刷新翻页。那么就用scroll不断通过游标获取下一页数据，这个性能是很高的，比es实际翻页要好的多的多。



## solr

### 基础概念类

1. 什么是 Solr，它有什么作用？
   - **答案**：Solr 是一个基于 Apache Lucene 的开源搜索服务器，它封装了 Lucene 的复杂操作，提供了简单易用的 RESTful API 接口。其作用主要是构建高效的搜索功能，能对大量数据进行索引和搜索，广泛应用于电商网站的商品搜索、新闻网站的文章搜索等场景。
2. 请简要介绍 Solr 的架构。
   - **答案**：Solr 架构主要由索引器、搜索器和分布式协调组件组成。索引器负责将数据进行分词、索引构建等操作并存储；搜索器接收用户的查询请求，在索引中进行查找并返回结果；分布式协调组件（如 ZooKeeper）用于在分布式环境下管理多个 Solr 节点，确保数据的一致性和高可用性。
3. Solr 中的核心（Core）是什么？
   - **答案**：Core 是 Solr 中独立的索引单元，每个 Core 有自己独立的配置文件和索引数据。可以将不同类型的数据分别存储在不同的 Core 中，例如一个电商应用可以将商品信息和用户评论分别存储在不同的 Core 里，方便管理和维护。

### 使用与配置类

1. 如何创建一个 Solr Core？
   - **答案**：可以通过命令行或者 Solr 管理界面来创建 Core。使用命令行时，在 Solr 安装目录下执行相应命令，例如 `bin/solr create -c my_core` （`my_core` 为要创建的 Core 名称）。在管理界面创建时，登录 Solr 的管理界面，在 Cores 选项卡中点击 “Add Core” 按钮，按照提示填写相关信息即可。
2. 在 Solr 中如何进行数据导入？
   - **答案**：Solr 支持多种数据导入方式。可以使用 Solr 的 Data Import Handler（DIH）从关系型数据库（如 MySQL）中导入数据，需要在 `data-config.xml` 文件中配置数据源和查询语句；也可以通过 RESTful API 接口，将 JSON 或 XML 格式的数据直接发送到 Solr 进行索引；还可以使用 SolrJ（Java 客户端）编写代码进行数据导入。
3. 如何配置 Solr 的分词器？
   - **答案**：在 Solr 的 `schema.xml` 文件中进行分词器的配置。首先定义字段类型，然后在字段类型中指定分词器。例如，使用中文分词器 IKAnalyzer 时，需要引入相应的 JAR 包，并在 `schema.xml` 中配置字段类型如下：

xml

```xml
<fieldType name="text_ik" class="solr.TextField">
    <analyzer type="index">
        <tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory" useSmart="false"/>
    </analyzer>
    <analyzer type="query">
        <tokenizer class="org.wltea.analyzer.lucene.IKTokenizerFactory" useSmart="true"/>
    </analyzer>
</fieldType>
```

### 性能优化类

1. 如何优化 Solr 的搜索性能？
   - **答案**：可以从多个方面进行优化。在索引方面，合理设置索引的分片和副本数量，避免索引文件过大；使用合适的分词器和过滤器，减少索引的冗余数据。在查询方面，优化查询语句，避免复杂的查询和全量扫描；使用缓存机制，如查询缓存和字段缓存，减少重复查询的开销。还可以对 Solr 服务器的硬件资源进行优化，如增加内存、使用高速磁盘等。
2. Solr 中的缓存有哪些类型，如何配置？
   - **答案**：Solr 主要有查询缓存（QueryResultCache）、过滤器缓存（FilterCache）和字段缓存（FieldValueCache）。可以在 `solrconfig.xml` 文件中进行缓存的配置。例如，配置查询缓存：



xml

```xml
<queryResultCache class="solr.LRUCache" size="512" initialSize="128" autowarmCount="0"/>
```



其中，`size` 表示缓存的最大条目数，`initialSize` 表示初始条目数，`autowarmCount` 表示预热条目数。

### 分布式与集群类

1. Solr 如何实现分布式搜索？
   - **答案**：Solr 通过分片（Sharding）和副本（Replica）机制实现分布式搜索。将索引数据分成多个分片，每个分片可以有多个副本，分布在不同的 Solr 节点上。使用 ZooKeeper 进行分布式协调，管理节点的状态和数据的一致性。当接收到查询请求时，请求会被分发到各个相关的分片上进行搜索，然后将结果合并返回给用户。
2. 在 Solr 集群中，如何处理节点故障？
   - **答案**：由于每个分片有多个副本，当某个节点出现故障时，ZooKeeper 会检测到节点的状态变化，并将该节点上的副本标记为不可用。同时，其他正常节点上的副本可以继续提供服务，保证搜索的可用性。在故障节点恢复后，ZooKeeper 会重新分配副本，恢复数据的一致性。

### 与其他工具对比类

1. Solr 和 Elasticsearch 有什么区别？
   - **答案**：Solr 出现较早，有成熟的企业级解决方案和丰富的功能，适合对功能需求复杂、对稳定性要求高的场景。它在配置和管理上相对复杂，需要更多的手动操作。Elasticsearch 基于分布式架构设计，具有更好的扩展性和实时性，易于上手和快速搭建。它在大数据处理和实时搜索方面表现更出色。
2. 在什么情况下选择 Solr 而不是 Elasticsearch？
   - **答案**：如果项目对搜索功能的定制化需求较高，需要使用 Solr 丰富的插件和配置选项；或者项目已经有成熟的 Java 技术栈，Solr 与 Java 的集成更方便；又或者对搜索的稳定性和可靠性要求极高，Solr 经过多年的发展在企业级应用中更加稳定，此时可以选择 Solr。



=======
# Elasticsearch与Solr技术剖析
## Elasticsearch
### 基础概念
Elasticsearch是一款集实时性、分布式、搜索和分析功能于一身的引擎。它基于Lucene构建，不仅提供了HTTP Web交互界面，还支持无架构的JSON文档，实现了分布式、多租户模式的全文搜索。Elasticsearch采用Java开发，遵循Apache许可条款，以开源形式发布。

### 组成结构
1. **集群（Cluster）**：由一个或多个节点组成，这些节点协同存储全部数据，并在所有节点间实现联合索引与搜索。每个集群通过唯一名称标识，默认名称为“elasticsearch”。集群名称至关重要，节点依据此名称加入对应的集群。
2. **节点（Node）**：作为集群的一部分，单个服务器即为一个节点。节点负责存储数据，并参与集群的索引和搜索操作。
3. **索引（Index）**：类似于关系数据库中的“数据库”，索引定义了多种类型的映射。它是一个逻辑名称空间，映射到一个或多个主分片，同时可以拥有零个或多个副本分片。对比关系数据库，MySQL的数据库等同于Elasticsearch的索引。
4. **文档（Document）**：类似于关系数据库中的行。不同的是，索引中的每个文档结构可以不同，但相同字段的数据类型需保持一致。以数据结构类比，MySQL的数据库 - 表 - 列/行，对应Elasticsearch的索引 - 类型 - 带属性的文档。
5. **类型（Type）**：是索引的逻辑分类或分区，其具体语义由用户自行定义。

### 核心思想
#### 倒排索引
倒排索引是搜索引擎的核心组件，其本质是一种哈希图结构。它将单词与包含该单词的文档或网页建立映射关系，主要用于从海量文件中快速定位满足搜索条件的文档，极大提升搜索效率。

### 分布式存储原理
1. **分片机制**：Elasticsearch将索引拆分为多个分片，每个分片都是一个独立的Lucene索引，承载索引数据的一部分。创建索引时，可指定主分片数量。例如，创建包含5个主分片的索引，数据会均匀分布到这5个分片上，实现多节点并行处理数据，提升存储和查询性能。
2. **副本机制**：为保障数据的高可用性和容错性，Elasticsearch引入副本概念。每个主分片可拥有零个或多个副本分片，副本分片是主分片的拷贝，且存储在不同节点上。当主分片所在节点故障时，副本分片可自动提升为主分片继续服务，同时副本分片也能处理查询请求，增强系统并发处理能力。
3. **集群协调与发现**：Elasticsearch集群节点通过内置的分布式协调机制进行通信协作。节点间使用gossip协议相互发现，并通过选举产生主节点。主节点负责管理集群元数据，如索引的创建、删除以及分片分配等，其他节点则专注于数据的存储和处理。

### 查询与聚合
#### 查询语句类型
1. **全文搜索查询**：用于在文本字段中执行全文搜索，常见的有match查询、multi_match查询等。
2. **精确匹配查询**：针对精确值字段进行精确匹配，如term查询、terms查询等。
3. **范围查询**：在数字或日期字段上进行范围查找，典型的如range查询。
4. **布尔查询**：通过组合多个查询条件，实现复杂查询逻辑，包含must、should、must_not等操作。

#### 聚合
聚合功能用于对数据进行分组、统计和分析。例如，在包含产品信息的索引中，通过“category”字段对产品进行分组，统计每个类别的产品数量，示例如下：

```json
{
    "aggs": {
        "category_count": {
            "terms": {
                "field": "category"
            }
        }
    }
}
```

### 其他关键知识点
1. **分词与模糊匹配**：Elasticsearch实现快速“模糊匹配”和“相关性查询”的基础是分词。写入数据时，系统会对数据进行分词处理。例如，对于包含“算法”一词的文档，Elasticsearch会建立“算法”与文档页码的映射，如“算法 -> 2,13,42,56”，从而基于倒排索引实现高效搜索。
2. **分词器**：Elasticsearch内置多种分词器，如Standard Analyzer按词切分并将词小写；Simple Analyzer按非字母过滤并将词小写；WhitespaceAnalyzer按空格切分且不转小写。分词器主要由Character Filters（去除HTML等文本过滤器）、Tokenizer（按规则切分，如按空格）和TokenFilter（对切分后的词进行处理，如转小写）三部分组成。由于内置分词器多针对英文，中文分词常用IK分词器。
3. **使用场景**：在商城场景中，数据量庞大，传统模糊查询会导致全表扫描，效率低下。而Elasticsearch通过建立全文索引，将商品名、描述、价格和ID等常用查询字段纳入索引库，大幅提升查询速度。
4. **Master选举**：Elasticsearch的选主由ZenDiscovery模块负责，该模块包含Ping（节点间用于相互发现的RPC）和Unicast（包含控制节点Ping通的主机列表）两部分。选举时，对所有可成为master的节点（node.master: true）按nodeId字典排序，每个节点对已知节点排序后选取第一个节点作为临时master。当某个节点获得超过半数（n/2 + 1）的投票且自投一票时，该节点成为master，否则重新选举。Master节点主要负责集群、节点和索引的管理，不涉及文档级管理，data节点可关闭http功能。
5. **脑裂问题处理**：当集群中有20个节点，出现10个节点选一个master，另外10个节点选另一个master的情况时，若集群master候选数量不小于3个，可通过设置discovery.zen.minimum_master_nodes超过所有候选节点一半以上来解决脑裂问题；若候选数量为两个，需将其中一个设为唯一master候选，另一个作为data节点，避免脑裂。
6. **索引文档过程**：协调节点默认使用文档ID参与计算（也支持routing）确定分片，计算公式为shard = hash(document_id) % (num_of_primary_shards)。分片所在节点接收请求后，将数据写入Memory Buffer，默认每隔1秒写入Filesystem Cache，此过程称为refresh。为保证数据可靠性，系统引入translog机制，接收到请求时同时写入translog，当Filesystem Cache中的数据写入磁盘后清除translog，此过程称为flush。Flush操作会清除内存缓冲，将内容写入新段，执行fsync创建新提交点并刷新到磁盘，同时删除旧的translog。Flush操作定时触发（默认30分钟）或在translog过大（默认为512M）时触发。
7. **更新和删除文档过程**：Elasticsearch中的文档不可变，删除和更新操作并非真正删除或修改文档。删除时，文档在.del文件中被标记为删除，仍可匹配查询但会在结果中过滤；更新时，旧版本文档在.del文件中标记为删除，新版本文档索引到新段。段合并时，被标记删除的文档不会写入新段。
8. **搜索过程**：搜索分Query Then Fetch两个阶段。Query阶段，查询请求广播到索引的每个分片拷贝（主分片或副本分片），每个分片在本地执行搜索并构建大小为from + size的匹配文档优先队列。此阶段会查询Filesystem Cache，但由于部分数据还在Memory Buffer，搜索具有近实时性。每个分片将优先队列中的文档ID和排序值返回给协调节点，协调节点合并这些值生成全局排序结果列表。Fetch阶段，协调节点确定需取回的文档并向相关分片发送多个GET请求，分片加载并丰富文档后返回给协调节点，协调节点将结果返回客户端。此外，DFS Query Then Fetch增加预查询处理，获取Term和Document frequency，使评分更准确，但性能会有所下降。
9. **大数据量聚合实现**：Elasticsearch的cardinality度量是一种近似聚合方法，基于HLL算法实现。该算法先对输入进行哈希运算，再根据哈希结果的bits进行概率估算得到基数。其具有可配置精度以控制内存使用（精度越高，内存消耗越大）、小数据集精度高的特点，可通过配置参数设置去重所需的固定内存量。
10. **读写一致性保证**：并发情况下，Elasticsearch通过版本号实现乐观并发控制，防止新版本被旧版本覆盖，冲突处理由应用层负责。写操作的一致性级别支持quorum/one/all，默认quorum，即多数分片可用时才允许写操作。若写入副本失败，该副本被视为故障，分片将在其他节点重建。读操作可设置replication为sync（默认），确保主分片和副本分片都完成操作后返回；也可设置为async，并通过设置搜索请求参数_preference为primary查询主分片，保证获取最新版本文档。
11. **分片与架构**：索引通常分割为分布在多个节点上的分片，每个节点独立运行在盒子或虚拟机上。Elasticsearch支持架构定义，通过映射描述JSON文档中的字段及其数据类型，以及在Lucene索引中的索引方式。Elasticsearch具有灵活的架构能力，可在不指定映射的情况下动态生成映射。
12. **副本与分析器**：索引分解为分片以实现分发和扩展，副本是分片的拷贝。索引数据时，数据由为索引定义的Analyzer进行内部转换，Analyzer由Tokenizer和零个或多个TokenFilter组成，可在一个或多个CharFilter之前。Elasticsearch提供多种预建分析器，也支持组合内置组件创建自定义分析器。
13. **编译器与相关属性**：编译器用于将字符串分解为术语或标记流，Elasticsearch提供多种内置标记器。enabled属性适用于Elasticsearch特定领域，存储属性决定数据是否由Lucene存储并可返回，索引属性用于搜索。索引字段在分析过程中会转换，因此无法检索原始数据。
14. **大数据量查询效率优化**
    - **filesystem cache优化**：Elasticsearch搜索引擎严重依赖文件系统缓存，写入的数据最终存储在磁盘上。若filesystem cache内存充足，搜索可直接从内存读取，性能大幅提升。例如，3节点集群，每台机器64G内存，给Elasticsearch JVM heap分配32G，剩余32G留给filesystem cache，集群共96G cache内存。若数据量为1T，仅10%的索引文件可存入cache，效率较低。因此，机器内存应至少容纳总数据量的一半。
    - **数据预热与冷热分离**：当file cache内存无法容纳全部数据时，可通过后台系统定时拉取热门数据进行预热，利用查询时Elasticsearch记录索引信息并排序放入file cache的特性，提高热门数据的缓存命中率。同时，可将大量不常用的冷数据字段拆分到其他索引中，实现冷热分离，确保热数据尽可能留在filesystem os cache中，提升热数据的访问性能。
    - **document模型设计优化**：避免在Elasticsearch中使用复杂的关联查询语法，因为这通常会导致性能下降。对于有关联的数据，可写入不同索引，如将订单和订单项数据分别写入order索引和orderItem索引，减少Elasticsearch复杂查询的使用。
    - **分页性能优化**：Elasticsearch的分页机制存在性能问题，如查询第100页（每页10条数据）时，每个shard需返回前1000条数据，5个shard共返回5000条数据，协调节点对这些数据进行合并处理后才能获取第100页的10条数据，翻页越深性能越差。可采用两种优化方案：一是不允许分页，直接将数据返回给客户端；二是使用scroll api，通过保留数据快照，在一定时间内通过游标获取下一页数据，提升分页性能。

## Solr
### 主要特点
1. **高性能**：Solr基于Lucene开发，借助Lucene的高效索引和搜索算法，能够快速处理大量数据的索引和查询请求。通过优化存储结构和查询执行引擎，在高并发场景下也能迅速返回搜索结果。
2. **可扩展性**：支持分布式部署，通过水平扩展服务器节点，可应对不断增长的数据量和查询负载。它将索引数据分散存储在多个节点上，利用集群管理机制实现数据一致性和负载均衡，确保系统在大规模数据和高并发环境下稳定运行。
3. **丰富的查询功能**：提供多种查询语法和过滤器，包括全文搜索、范围查询、布尔查询、地理位置查询等。用户可根据业务需求灵活组合查询条件，实现精准搜索。此外，Solr支持自定义查询插件，满足特定业务场景的查询需求。
4. **高可用性**：具备容错和故障转移机制，当集群中某个节点故障时，Solr可自动将请求路由到其他正常节点，保证服务的连续性。同时，通过数据副本复制，提高数据的可靠性，防止数据丢失。
5. **易于管理**：提供直观的Web管理界面，方便管理员进行索引、查询、配置等管理和监控操作。管理员可通过界面轻松创建、修改和删除索引，查看系统状态和性能指标，调整配置参数。此外，Solr还支持命令行工具和RESTful API，便于开发者进行自动化管理和集成。

### 应用场景
1. **电子商务搜索**：在电商平台中，Solr可用于商品搜索，支持根据商品名称、描述、价格、类别等多个维度进行搜索，并提供商品排序、筛选和推荐功能，提升用户购物体验。
2. **企业信息检索**：企业内部存在大量文档、数据和信息，Solr可构建企业级搜索系统，实现对文档、邮件、知识库等内容的全文搜索，提高员工获取信息的效率。
3. **日志分析**：对于大型系统产生的海量日志数据，Solr可进行实时索引和查询。通过分析日志数据，企业可及时发现系统故障、安全问题和业务异常，为系统监控和优化提供支持。
4. **社交媒体搜索**：在社交媒体平台中，Solr可用于用户搜索、话题搜索和内容推荐等功能。它能处理大量用户生成内容，如帖子、评论、图片等，并根据用户兴趣和行为提供个性化搜索结果。

### 局限性
1. **实时性处理相对较弱**：尽管Solr能处理实时数据，但在对实时性要求极高的场景下，其索引更新和查询响应可能存在一定延迟，性能不如一些专门的实时搜索系统。
2. **复杂查询处理能力有限**：对于涉及多表关联和嵌套查询的复杂业务逻辑，Solr的处理能力可能受限，通常需要结合其他数据库系统来完成复杂查询。
>>>>>>> origin/main
