# Elasticsearch与Solr技术剖析
## Elasticsearch
### 基础概念
Elasticsearch是一款集实时性、分布式、搜索和分析功能于一身的引擎。它基于Lucene构建，不仅提供了HTTP Web交互界面，还支持无架构的JSON文档，实现了分布式、多租户模式的全文搜索。Elasticsearch采用Java开发，遵循Apache许可条款，以开源形式发布。

### 组成结构
1. **集群（Cluster）**：由一个或多个节点组成，这些节点协同存储全部数据，并在所有节点间实现联合索引与搜索。每个集群通过唯一名称标识，默认名称为“elasticsearch”。集群名称至关重要，节点依据此名称加入对应的集群。
2. **节点（Node）**：作为集群的一部分，单个服务器即为一个节点。节点负责存储数据，并参与集群的索引和搜索操作。
3. **索引（Index）**：类似于关系数据库中的“数据库”，索引定义了多种类型的映射。它是一个逻辑名称空间，映射到一个或多个主分片，同时可以拥有零个或多个副本分片。对比关系数据库，MySQL的数据库等同于Elasticsearch的索引。
4. **文档（Document）**：类似于关系数据库中的行。不同的是，索引中的每个文档结构可以不同，但相同字段的数据类型需保持一致。以数据结构类比，MySQL的数据库 - 表 - 列/行，对应Elasticsearch的索引 - 类型 - 带属性的文档。
5. **类型（Type）**：是索引的逻辑分类或分区，其具体语义由用户自行定义。

### 核心思想
#### 倒排索引
倒排索引是搜索引擎的核心组件，其本质是一种哈希图结构。它将单词与包含该单词的文档或网页建立映射关系，主要用于从海量文件中快速定位满足搜索条件的文档，极大提升搜索效率。

### 分布式存储原理
1. **分片机制**：Elasticsearch将索引拆分为多个分片，每个分片都是一个独立的Lucene索引，承载索引数据的一部分。创建索引时，可指定主分片数量。例如，创建包含5个主分片的索引，数据会均匀分布到这5个分片上，实现多节点并行处理数据，提升存储和查询性能。
2. **副本机制**：为保障数据的高可用性和容错性，Elasticsearch引入副本概念。每个主分片可拥有零个或多个副本分片，副本分片是主分片的拷贝，且存储在不同节点上。当主分片所在节点故障时，副本分片可自动提升为主分片继续服务，同时副本分片也能处理查询请求，增强系统并发处理能力。
3. **集群协调与发现**：Elasticsearch集群节点通过内置的分布式协调机制进行通信协作。节点间使用gossip协议相互发现，并通过选举产生主节点。主节点负责管理集群元数据，如索引的创建、删除以及分片分配等，其他节点则专注于数据的存储和处理。

### 查询与聚合
#### 查询语句类型
1. **全文搜索查询**：用于在文本字段中执行全文搜索，常见的有match查询、multi_match查询等。
2. **精确匹配查询**：针对精确值字段进行精确匹配，如term查询、terms查询等。
3. **范围查询**：在数字或日期字段上进行范围查找，典型的如range查询。
4. **布尔查询**：通过组合多个查询条件，实现复杂查询逻辑，包含must、should、must_not等操作。

#### 聚合
聚合功能用于对数据进行分组、统计和分析。例如，在包含产品信息的索引中，通过“category”字段对产品进行分组，统计每个类别的产品数量，示例如下：

```json
{
    "aggs": {
        "category_count": {
            "terms": {
                "field": "category"
            }
        }
    }
}
```

### 其他关键知识点
1. **分词与模糊匹配**：Elasticsearch实现快速“模糊匹配”和“相关性查询”的基础是分词。写入数据时，系统会对数据进行分词处理。例如，对于包含“算法”一词的文档，Elasticsearch会建立“算法”与文档页码的映射，如“算法 -> 2,13,42,56”，从而基于倒排索引实现高效搜索。
2. **分词器**：Elasticsearch内置多种分词器，如Standard Analyzer按词切分并将词小写；Simple Analyzer按非字母过滤并将词小写；WhitespaceAnalyzer按空格切分且不转小写。分词器主要由Character Filters（去除HTML等文本过滤器）、Tokenizer（按规则切分，如按空格）和TokenFilter（对切分后的词进行处理，如转小写）三部分组成。由于内置分词器多针对英文，中文分词常用IK分词器。
3. **使用场景**：在商城场景中，数据量庞大，传统模糊查询会导致全表扫描，效率低下。而Elasticsearch通过建立全文索引，将商品名、描述、价格和ID等常用查询字段纳入索引库，大幅提升查询速度。
4. **Master选举**：Elasticsearch的选主由ZenDiscovery模块负责，该模块包含Ping（节点间用于相互发现的RPC）和Unicast（包含控制节点Ping通的主机列表）两部分。选举时，对所有可成为master的节点（node.master: true）按nodeId字典排序，每个节点对已知节点排序后选取第一个节点作为临时master。当某个节点获得超过半数（n/2 + 1）的投票且自投一票时，该节点成为master，否则重新选举。Master节点主要负责集群、节点和索引的管理，不涉及文档级管理，data节点可关闭http功能。
5. **脑裂问题处理**：当集群中有20个节点，出现10个节点选一个master，另外10个节点选另一个master的情况时，若集群master候选数量不小于3个，可通过设置discovery.zen.minimum_master_nodes超过所有候选节点一半以上来解决脑裂问题；若候选数量为两个，需将其中一个设为唯一master候选，另一个作为data节点，避免脑裂。
6. **索引文档过程**：协调节点默认使用文档ID参与计算（也支持routing）确定分片，计算公式为shard = hash(document_id) % (num_of_primary_shards)。分片所在节点接收请求后，将数据写入Memory Buffer，默认每隔1秒写入Filesystem Cache，此过程称为refresh。为保证数据可靠性，系统引入translog机制，接收到请求时同时写入translog，当Filesystem Cache中的数据写入磁盘后清除translog，此过程称为flush。Flush操作会清除内存缓冲，将内容写入新段，执行fsync创建新提交点并刷新到磁盘，同时删除旧的translog。Flush操作定时触发（默认30分钟）或在translog过大（默认为512M）时触发。
7. **更新和删除文档过程**：Elasticsearch中的文档不可变，删除和更新操作并非真正删除或修改文档。删除时，文档在.del文件中被标记为删除，仍可匹配查询但会在结果中过滤；更新时，旧版本文档在.del文件中标记为删除，新版本文档索引到新段。段合并时，被标记删除的文档不会写入新段。
8. **搜索过程**：搜索分Query Then Fetch两个阶段。Query阶段，查询请求广播到索引的每个分片拷贝（主分片或副本分片），每个分片在本地执行搜索并构建大小为from + size的匹配文档优先队列。此阶段会查询Filesystem Cache，但由于部分数据还在Memory Buffer，搜索具有近实时性。每个分片将优先队列中的文档ID和排序值返回给协调节点，协调节点合并这些值生成全局排序结果列表。Fetch阶段，协调节点确定需取回的文档并向相关分片发送多个GET请求，分片加载并丰富文档后返回给协调节点，协调节点将结果返回客户端。此外，DFS Query Then Fetch增加预查询处理，获取Term和Document frequency，使评分更准确，但性能会有所下降。
9. **大数据量聚合实现**：Elasticsearch的cardinality度量是一种近似聚合方法，基于HLL算法实现。该算法先对输入进行哈希运算，再根据哈希结果的bits进行概率估算得到基数。其具有可配置精度以控制内存使用（精度越高，内存消耗越大）、小数据集精度高的特点，可通过配置参数设置去重所需的固定内存量。
10. **读写一致性保证**：并发情况下，Elasticsearch通过版本号实现乐观并发控制，防止新版本被旧版本覆盖，冲突处理由应用层负责。写操作的一致性级别支持quorum/one/all，默认quorum，即多数分片可用时才允许写操作。若写入副本失败，该副本被视为故障，分片将在其他节点重建。读操作可设置replication为sync（默认），确保主分片和副本分片都完成操作后返回；也可设置为async，并通过设置搜索请求参数_preference为primary查询主分片，保证获取最新版本文档。
11. **分片与架构**：索引通常分割为分布在多个节点上的分片，每个节点独立运行在盒子或虚拟机上。Elasticsearch支持架构定义，通过映射描述JSON文档中的字段及其数据类型，以及在Lucene索引中的索引方式。Elasticsearch具有灵活的架构能力，可在不指定映射的情况下动态生成映射。
12. **副本与分析器**：索引分解为分片以实现分发和扩展，副本是分片的拷贝。索引数据时，数据由为索引定义的Analyzer进行内部转换，Analyzer由Tokenizer和零个或多个TokenFilter组成，可在一个或多个CharFilter之前。Elasticsearch提供多种预建分析器，也支持组合内置组件创建自定义分析器。
13. **编译器与相关属性**：编译器用于将字符串分解为术语或标记流，Elasticsearch提供多种内置标记器。enabled属性适用于Elasticsearch特定领域，存储属性决定数据是否由Lucene存储并可返回，索引属性用于搜索。索引字段在分析过程中会转换，因此无法检索原始数据。
14. **大数据量查询效率优化**
    - **filesystem cache优化**：Elasticsearch搜索引擎严重依赖文件系统缓存，写入的数据最终存储在磁盘上。若filesystem cache内存充足，搜索可直接从内存读取，性能大幅提升。例如，3节点集群，每台机器64G内存，给Elasticsearch JVM heap分配32G，剩余32G留给filesystem cache，集群共96G cache内存。若数据量为1T，仅10%的索引文件可存入cache，效率较低。因此，机器内存应至少容纳总数据量的一半。
    - **数据预热与冷热分离**：当file cache内存无法容纳全部数据时，可通过后台系统定时拉取热门数据进行预热，利用查询时Elasticsearch记录索引信息并排序放入file cache的特性，提高热门数据的缓存命中率。同时，可将大量不常用的冷数据字段拆分到其他索引中，实现冷热分离，确保热数据尽可能留在filesystem os cache中，提升热数据的访问性能。
    - **document模型设计优化**：避免在Elasticsearch中使用复杂的关联查询语法，因为这通常会导致性能下降。对于有关联的数据，可写入不同索引，如将订单和订单项数据分别写入order索引和orderItem索引，减少Elasticsearch复杂查询的使用。
    - **分页性能优化**：Elasticsearch的分页机制存在性能问题，如查询第100页（每页10条数据）时，每个shard需返回前1000条数据，5个shard共返回5000条数据，协调节点对这些数据进行合并处理后才能获取第100页的10条数据，翻页越深性能越差。可采用两种优化方案：一是不允许分页，直接将数据返回给客户端；二是使用scroll api，通过保留数据快照，在一定时间内通过游标获取下一页数据，提升分页性能。

## Solr
### 主要特点
1. **高性能**：Solr基于Lucene开发，借助Lucene的高效索引和搜索算法，能够快速处理大量数据的索引和查询请求。通过优化存储结构和查询执行引擎，在高并发场景下也能迅速返回搜索结果。
2. **可扩展性**：支持分布式部署，通过水平扩展服务器节点，可应对不断增长的数据量和查询负载。它将索引数据分散存储在多个节点上，利用集群管理机制实现数据一致性和负载均衡，确保系统在大规模数据和高并发环境下稳定运行。
3. **丰富的查询功能**：提供多种查询语法和过滤器，包括全文搜索、范围查询、布尔查询、地理位置查询等。用户可根据业务需求灵活组合查询条件，实现精准搜索。此外，Solr支持自定义查询插件，满足特定业务场景的查询需求。
4. **高可用性**：具备容错和故障转移机制，当集群中某个节点故障时，Solr可自动将请求路由到其他正常节点，保证服务的连续性。同时，通过数据副本复制，提高数据的可靠性，防止数据丢失。
5. **易于管理**：提供直观的Web管理界面，方便管理员进行索引、查询、配置等管理和监控操作。管理员可通过界面轻松创建、修改和删除索引，查看系统状态和性能指标，调整配置参数。此外，Solr还支持命令行工具和RESTful API，便于开发者进行自动化管理和集成。

### 应用场景
1. **电子商务搜索**：在电商平台中，Solr可用于商品搜索，支持根据商品名称、描述、价格、类别等多个维度进行搜索，并提供商品排序、筛选和推荐功能，提升用户购物体验。
2. **企业信息检索**：企业内部存在大量文档、数据和信息，Solr可构建企业级搜索系统，实现对文档、邮件、知识库等内容的全文搜索，提高员工获取信息的效率。
3. **日志分析**：对于大型系统产生的海量日志数据，Solr可进行实时索引和查询。通过分析日志数据，企业可及时发现系统故障、安全问题和业务异常，为系统监控和优化提供支持。
4. **社交媒体搜索**：在社交媒体平台中，Solr可用于用户搜索、话题搜索和内容推荐等功能。它能处理大量用户生成内容，如帖子、评论、图片等，并根据用户兴趣和行为提供个性化搜索结果。

### 局限性
1. **实时性处理相对较弱**：尽管Solr能处理实时数据，但在对实时性要求极高的场景下，其索引更新和查询响应可能存在一定延迟，性能不如一些专门的实时搜索系统。
2. **复杂查询处理能力有限**：对于涉及多表关联和嵌套查询的复杂业务逻辑，Solr的处理能力可能受限，通常需要结合其他数据库系统来完成复杂查询。
